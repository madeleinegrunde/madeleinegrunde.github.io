---
permalink: /
title: "Madeleine Grunde-McLaughin"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello! 

I am a third year Ph.D. student in Computer Science at the University of Washington under the guidance of [Jeffrey Heer](https://homes.cs.washington.edu/~jheer/) and [Daniel Weld](https://www.cs.washington.edu/people/faculty/weld). 

Iâ€™m motivated to make AI-backed tools work for people. How can we make technology that is quickly adaptable to novel and specific domains? How can we bridge the communication gap between researchers, developers, and domain experts? How can we support oversight of AI systems by people with limited background in the technology?

I am especially interested in exploring these questions related to environmental and data science applications.

[Curriculum Vitae](CV.pdf) - [Google Scholar](https://scholar.google.com/citations?user=wzqKsd4AAAAJ&hl=en&oi=ao) - [mgrunde at cs.washington.edu](mailto:mgrunde@cs.washington.edu)


<br/>


Publications
======

**Explanations can Reduce Overreliance on AI Systems during Decision-Making** \
*Helena Vasconcelos, Matthew Jorke, **Madeleine Grunde-McLaughlin**, Ranjay Krishna, Tobias Gerstenberg, Michael S. Bernstein* \
ACM Conference on Computer-Supported Cooperative Work and Social Computing, 2023\
[paper](https://arxiv.org/abs/2212.06823)

**Measuring Compositional Consistency for Video Question Answering** \
*Mona Gandhi, Mustafa Omer Gul, Eva Prakash, **Madeleine Grunde-McLaughlin**, Ranjay Krishna, Maneesh Agrawala*\
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022\
[paper](https://arxiv.org/pdf/2204.07190.pdf), [benchmark data](https://agqa-decomp.cs.washington.edu/)

**AGQA: A Compositional Benchmark for Spatio-Temporal Reasoning** \
***Madeleine Grunde-McLaughlin**, Ranjay Krishna, Maneesh Agrawala*\
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021\
[paper](https://arxiv.org/pdf/2103.16002.pdf), [benchmark data](https://cs.stanford.edu/people/ranjaykrishna/agqa/), [video](https://www.youtube.com/watch?v=6Rw1QF9Hono), [blog post](http://ai.stanford.edu/blog/agqa/)

**Bayesian-Assisted Inference from Visualized Data**\
*Yea-Seul Kim, Paula Kayongo, **Madeleine Grunde-McLaughlin**, Jessica Hullman*\
IEEE InfoVis 2020\
[paper](https://arxiv.org/pdf/2008.00142.pdf)

<br/>


Preprints and workshop papers
======

**Designing LLM Chains by Adapting Techniques from Crowdsourcing Workflows** \
***Madeleine Grunde-McLaughlin**, Michelle S Lam, Ranjay Krishna, Daniel S Weld, Jeffrey Heer* \
ArXiv, 2023\
[paper](https://arxiv.org/abs/2312.11681)


**How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study** \
*Ken Gu, **Madeleine Grunde-McLaughlin**, Andrew M McNutt, Jeffrey Heer, Tim Althoff* \
Conditionally Accepted at ACM Conference on Human Computer Interaction, 2024\
[paper](https://arxiv.org/abs/2309.10108)

**Semantic Navigator: Query Driven Active Learning for Historical Narrative Understanding** \
*Eva Maxfield Brown, **Madeleine Grunde-McLaughlin**, Isabelle Pestovski, Lanyi Zhu, Nicholas Weber* \
ACM Conference on Computer-Supported Cooperative Work and Social Computing, Community-Driven AI Workshop, 2023 \
[paper](CSCW-2023-workshop.pdf)

**When do XAI Methods Work? A Cost-Benefit Approach to Human-AI Collaboration** \
*Helena Vasconcelos, Matthew Jorke, **Madeleine Grunde-McLaughlin**, Ranjay Krishna, Tobias Gerstenberg, Michael S. Bernstein* \
TRAIT Workshop at ACM Conference on Human Computer Interaction, 2022\
[paper](https://chi-trait.github.io/papers/2022/CHI_TRAIT_2022_Paper_44.pdf)

**AGQA 2.0: An updated benchmark for compositional spatio-temporal reasoning** \
***Madeleine Grunde-McLaughlin**, Ranjay Krishna, Maneesh Agrawala* \
ArXiv, 2022\
[paper](https://arxiv.org/abs/2204.06105)

**Model Comparison of the Effects of Stimulus Structure on Visual Working Memory Recall**\
***Madeleine Grunde-McLaughlin**, Cheng Qiu, Alan Stocker* \
Honors Thesis in Cognitive Science\
Recipient of the College Alumni Society Prize in Cognitive Science, 2021\
[paper](Thesis.pdf)
